{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión con KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Entorno Scikit Learn\n",
    "from sklearn.neighbors import KNeighborsRegressor   # Algoritmo\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error      # Metrica de desempeño ( para ver que tan bien se ajusta nuestro modelo a los datos)\n",
    "from sklearn.model_selection import train_test_split    # Para dividir el conjunto de prueba y entrenamiento\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score   # Validación cruzada \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Para gráficos\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>63.2</td>\n",
       "      <td>168.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>68.7</td>\n",
       "      <td>169.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>176.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>67.9</td>\n",
       "      <td>246.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>68.9</td>\n",
       "      <td>151.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  height  weight\n",
       "0       0    63.2   168.7\n",
       "1       0    68.7   169.8\n",
       "2       0    64.8   176.6\n",
       "3       0    67.9   246.8\n",
       "4       1    68.9   151.6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos\n",
    "data=pd.read_csv(\"https://raw.githubusercontent.com/Albertuff/Machine-Learning/master/datos/estatura_peso.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El error absoluto promedio es: 32.3255 lbs\n",
      " El error cuadratico promedio es: 1699.5376 lbs^2\n",
      " La raíz cuadrada del error cuadratico promedio es: 41.2254 lbs\n"
     ]
    }
   ],
   "source": [
    "# Preprocesamiento\n",
    "\n",
    "#   Definimos los atributos y la variable de respuesta\n",
    "X=data[[\"height\"]]        # Atributo: Estatura\n",
    "Y=data[\"weight\"]        # Target o Respuesta: Peso   --  El target debe ser una variable continua cuando se usa KNN para regresión\n",
    "\n",
    "# Definimos el conjunto de entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,random_state=1234)\n",
    "\n",
    "# Definimos el modelo\n",
    "Modelo=KNeighborsRegressor(n_neighbors=7,n_jobs=-1)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "Modelo.fit(X_train,Y_train)\n",
    "\n",
    "# Realizamos las predicciones\n",
    "Y_pred=Modelo.predict(X_test)\n",
    "#print(Y_pred)\n",
    "#print(Y_test)\n",
    "\n",
    "# Que calificación le asignamos a nuestro modelo \n",
    "print(f\" El error absoluto promedio es: {mean_absolute_error(Y_test,Y_pred):.4f} lbs\")\n",
    "print(f\" El error cuadratico promedio es: {mean_squared_error(Y_test,Y_pred):.4f} lbs^2\")\n",
    "print(f\" La raíz cuadrada del error cuadratico promedio es: {mean_squared_error(Y_test,Y_pred,squared=False):.4f} lbs\") # squared=False regresa la raiz del error cuadratico promedio. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Los resultados dependen de varios factores:\n",
    " \n",
    " 1.- Las variables predictoras X, ¿Son adecuadas, ¿suficientes?, ¿unidades de medición?\n",
    "\n",
    " 2.- Los resultados dependen del conjunto de entrenamiento y prueba\n",
    " \n",
    " 3.- Los resultados dependen del valor del hiperparámetro k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El error absoluto promedio es: 32.2051 lbs\n",
      " El error cuadratico promedio es: 1690.6996 lbs^2\n",
      " La raíz cuadrada del error cuadratico promedio es: 41.1181 lbs\n"
     ]
    }
   ],
   "source": [
    "# Realizamos el preprocesamiento de las covariables o atributos\n",
    "# Vamos a hacer la tipificaxión de la variable estatura\n",
    "from sklearn import preprocessing\n",
    "z_score=preprocessing.StandardScaler()\n",
    "X=z_score.fit_transform(X)\n",
    "\n",
    "# Definimos el conjunto de entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,random_state=1234)\n",
    "\n",
    "# Definimos el modelo\n",
    "Modelo=KNeighborsRegressor(n_neighbors=7,n_jobs=-1)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "Modelo.fit(X_train,Y_train)\n",
    "\n",
    "# Realizamos las predicciones\n",
    "Y_pred=Modelo.predict(X_test)\n",
    "#print(Y_pred)\n",
    "#print(Y_test)\n",
    "\n",
    "# Que calificación le asignamos a nuestro modelo \n",
    "print(f\" El error absoluto promedio es: {mean_absolute_error(Y_test,Y_pred):.4f} lbs\")\n",
    "print(f\" El error cuadratico promedio es: {mean_squared_error(Y_test,Y_pred):.4f} lbs^2\")\n",
    "print(f\" La raíz cuadrada del error cuadratico promedio es: {mean_squared_error(Y_test,Y_pred,squared=False):.4f} lbs\") # squared=False regresa la raiz del error cuadratico promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El error absoluto promedio es: 33.9653 lbs\n",
      " El error cuadratico promedio es: 1805.0755 lbs^2\n",
      " La raíz cuadrada del error cuadratico promedio es: 42.4862 lbs\n"
     ]
    }
   ],
   "source": [
    "# Calcular una metrica y calibrar el modelo tiene el error de que el conjunto de prueba y entrenamiento están relacionados\n",
    "#  porque se estandarizaron utilizando los valores globales de la media y la varianza\n",
    "\n",
    "# Primero hacemos la división del conjunto de entrenamiento y prueba\n",
    "train, test=train_test_split(data,test_size=0.2,random_state=1234)\n",
    "\n",
    "# Definimos los atributos y la variable de respuesta\n",
    "X_train=train[[\"height\"]]\n",
    "Y_train=train[\"weight\"]\n",
    "X_test=test[[\"height\"]]\n",
    "Y_test=test[\"weight\"]\n",
    "\n",
    "# Vamos a hacer la tipificaxión de la variable estatura\n",
    "z_score=preprocessing.StandardScaler()\n",
    "X_train=z_score.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# Definimos el modelo\n",
    "Modelo=KNeighborsRegressor(n_neighbors=7,n_jobs=-1)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "Modelo.fit(X_train,Y_train)\n",
    "\n",
    "# Realizamos las predicciones, primero tipificando los datos\n",
    "X_test=z_score.fit_transform(X_test)\n",
    "Y_pred=Modelo.predict(X_test)\n",
    "#print(Y_pred)\n",
    "#print(Y_test)\n",
    "\n",
    "# Que calificación le asignamos a nuestro modelo \n",
    "print(f\" El error absoluto promedio es: {mean_absolute_error(Y_test,Y_pred):.4f} lbs\")\n",
    "print(f\" El error cuadratico promedio es: {mean_squared_error(Y_test,Y_pred):.4f} lbs^2\")\n",
    "print(f\" La raíz cuadrada del error cuadratico promedio es: {mean_squared_error(Y_test,Y_pred,squared=False):.4f} lbs\") # squared=False regresa la raiz del error cuadratico promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " La mejor configuración de k es: {'n_neighbors': 7}\n",
      " El error absoluto promedio es : 23.71265306\n"
     ]
    }
   ],
   "source": [
    "# Buscamos el valor de k con el cual obtenemos el mejor desempeño\n",
    "# Definimos los atributos y la variable objertivo\n",
    "X=data[[\"height\"]]\n",
    "Y=data[\"weight\"]\n",
    "\n",
    "parametros={\"n_neighbors\":np.arange(1,50)}   # Buscamos el mejor valor de k, el numero de vecinos, entre 1 - 49\n",
    "                                             # El espacio de parametros está definido como un diccionario\n",
    "\n",
    "# El modelo que vamos a entrenar es el de k vecinos mas cercanos\n",
    "modelo=KNeighborsRegressor()\n",
    "\n",
    "# Definimos el tipo de busqueda\n",
    "# Primero definimos la rejilla\n",
    "cv=KFold(n_splits=10)\n",
    "rejilla=GridSearchCV(modelo,param_grid=parametros,scoring=\"neg_mean_absolute_error\",cv=cv,n_jobs=-1)\n",
    "rejilla.fit(X,Y)\n",
    "\n",
    "print(f\" La mejor configuración de k es: {rejilla.best_params_}\")\n",
    "print(f\" El error absoluto promedio es : {mean_absolute_error(Y,rejilla.best_estimator_.predict(X)):.8f}\")\n",
    "\n",
    "# Hasta aquí ya tenemos el mejor modelo que es con 7 vecinos\n",
    "# Cual es el desempeño predictivo del modelo con 7 vecinos?, Lo podemos saber a travez de una validacion cruzada anidada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El desempeño predictivo promedio del mejor modelo es: 27.0405\n"
     ]
    }
   ],
   "source": [
    "# Realizamos una validación cruzada anidada\n",
    "\n",
    "# Definimos el esquema de validación cruzada interna. Que selecciona el mejor modelo\n",
    "cv_interna=KFold(n_splits=10)\n",
    "\n",
    "# Definimos la validacion cruzada externa, la cual permite calificar el desempeño predictivo del mejor modelo seleccionado\n",
    "cv_externa=KFold(n_splits=10)\n",
    "\n",
    "# El modelo a entrenar es k vecinos mas cercanos\n",
    "Modelofinal=KNeighborsRegressor()\n",
    "\n",
    "# Realizamos la busqueda de la mejor configuración\n",
    "rejilla=GridSearchCV(Modelofinal,param_grid=parametros,scoring=\"neg_mean_absolute_error\",n_jobs=-1,cv=cv_interna)\n",
    "\n",
    "# Ya que encontro el mejor modelo, lo entrena en el conjunto de entrenamiento y lo prueba en el conjunto de prueba\n",
    "scores=cross_val_score(rejilla,X,Y,cv=cv_externa,scoring=\"neg_mean_absolute_error\",n_jobs=-1)\n",
    "\n",
    "print(f\" El desempeño predictivo promedio del mejor modelo es: {-scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase 12 \n",
    "# Pipeline: O secuencia de funciones de preprocesamiento y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " La mejor configuración del hiperparámetro k es: {'Modelo__n_neighbors': 7}\n",
      " El mejor score (error absoluto promedio) es: 25.392857142857146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Primero se arreglan los datos faltantes si es que hay, luego se hace el reescalamiento y despues se agrega el modelo\n",
    "Pipe=Pipeline([(\"zscore\",preprocessing.StandardScaler()),(\"Modelo\",KNeighborsRegressor())]) #Los preocesos se definen como una lista\n",
    "# El hiperparámetro del modelo es: n_neighbors\n",
    "\n",
    "# Definimos el método de busqueda\n",
    "espacio_parametros={\"Modelo__n_neighbors\":np.arange(1,50)}  # Para pasar los hiperparámetros al pipe es necesario, anteponer al nomobre del hiperparámetro\n",
    "                                                            # el nombre que le estamos dando en el pipe a nuestro algoritmo, enn este caso: Modelo, seguido de dos guiones bajos\n",
    "                                                            # Modelo__\n",
    "\n",
    "rejilla=GridSearchCV(Pipe,param_grid=espacio_parametros,scoring=\"neg_mean_absolute_error\",n_jobs=-1,cv=10)\n",
    "rejilla.fit(X,Y)\n",
    "print(f\" La mejor configuración del hiperparámetro k es: {rejilla.best_params_}\")\n",
    "print(f\" El mejor score (error absoluto promedio) es: {-rejilla.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El mejor score (error absoluto promedio) es: 27.241248150676103\n"
     ]
    }
   ],
   "source": [
    "# Sabemos que este valor del score, es una metrica \"optimista\". Para tener uan metrica mas realista, hacemos una validacion cruzada anidada\n",
    "\n",
    "# cv_interna=KFold(n_splits=10)\n",
    "# cv_externa=KFold(n_splits=10)\n",
    "\n",
    "rejilla=GridSearchCV(Pipe,param_grid=espacio_parametros,scoring=\"neg_mean_absolute_error\",n_jobs=-1,cv=10)\n",
    "puntajes=cross_val_score(rejilla,X,Y,cv=10,scoring=\"neg_mean_absolute_error\",n_jobs=-1)\n",
    "print(f\" El mejor score (error absoluto promedio) es: {-puntajes.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El mejor score (error absoluto promedio) es: 27.50561641337778\n"
     ]
    }
   ],
   "source": [
    "# Otro tipo de validación cruzada\n",
    "\n",
    "cv_interna=KFold(n_splits=10)\n",
    "cv_externa=RepeatedKFold(n_splits=10,n_repeats=5)\n",
    "rejilla=GridSearchCV(Pipe,param_grid=espacio_parametros,scoring=\"neg_mean_absolute_error\",n_jobs=-1,cv=cv_interna)\n",
    "puntajes=cross_val_score(rejilla,X,Y,cv=cv_externa,scoring=\"neg_mean_absolute_error\",n_jobs=-1)\n",
    "print(f\" El mejor score (error absoluto promedio) es: {-puntajes.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7600a12950a547366bb7a6732117e300ffd26224351912980486e1126c5d0f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
